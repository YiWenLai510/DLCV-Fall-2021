{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "from torchvision.datasets import DatasetFolder\n",
    "import os\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        # self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.img_lists = sorted(os.listdir(self.img_dir))\n",
    "        # print(self.img_lists)\n",
    "    def __len__(self):\n",
    "        return len(self.img_lists)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.img_lists[idx]\n",
    "        img_path = os.path.join(self.img_dir, fileName)\n",
    "        image = Image.open(img_path)\n",
    "        label = fileName[:-4].split('_')[0]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = (self.target_transform(label))\n",
    "        # return imageName, image, label\n",
    "        return  (fileName, image, int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = myDataset(img_dir='hw1_data/p1_data/val_50',transform=test_tfm)\n",
    "dataloader = DataLoader(test_dataset, batch_size=128,shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_dir = 'p1_result.csv'\n",
    "\n",
    "model_path = 'save_models/64_50_vgg13_bn_cosineAnneal_changedata.pt'\n",
    "\n",
    "model = torchvision.models.vgg13_bn(pretrained=True)\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs,50)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(device)\n",
    "# print(model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "def hook(module, input, output):\n",
    "    features.append(output.clone().detach())\n",
    "\n",
    "handle = model.classifier[-2].register_forward_hook(hook)\n",
    "\n",
    "all_val = torch.empty((0,4096))\n",
    "targets = np.zeros((0,))\n",
    "for imgNames, imgs, labels in (dataloader):\n",
    "    labels = labels.detach().numpy()\n",
    "    # print(labels.shape)\n",
    "    targets = np.concatenate((labels,targets),axis=0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs.to(device))\n",
    "    all_val = torch.cat((all_val.cpu(),features[-1].cpu()),0)\n",
    "\n",
    "layerOut = all_val.detach().numpy()\n",
    "\n",
    "print(layerOut.shape,layerOut[0].shape)\n",
    "print(targets.shape,targets[0])\n",
    "# for f in features:\n",
    "#     all_val = torch.cat((all_val,f),0)\n",
    "handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "embedded = TSNE(n_components=2, learning_rate='auto',init='random').fit_transform(layerOut)\n",
    "print(embedded.shape)\n",
    "print(embedded[0])\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import cycle\n",
    "cycol = cycle('bgrcmk')\n",
    "\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "cmap = get_cmap(50)\n",
    "plt.figure(figsize=(16, 10))\n",
    "for label in range(50):\n",
    "    index = []\n",
    "    for i, t in enumerate(targets):\n",
    "        if t == label:\n",
    "            index.append(i)\n",
    "    plt.scatter(embedded[index,0], embedded[index,1], c=cmap(label), label=label) #next(cycol)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40ae9f67388871594583160bc250e6ac12bb8211fb020797ad1590c56e9dc544"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('dlcv_hw1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
